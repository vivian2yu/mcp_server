{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72a6df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install  arxiv\n",
    "# ! pip install dotenv\n",
    "# ! pip install anthropic\n",
    "# ! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbac1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPKey 配置\n",
    "# vi ~/.zshrc\n",
    "# export OPENAI_API_KEY=\"your_openai_api_key\"\n",
    "# export QWEN_API_KEY=\"your_qwen_api_key\"\n",
    "# source ~/.zshrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df192668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1920932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d58eaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b31ab2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c4f9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43e8ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_info('1310.7911v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1e7845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools for OpenAI and Anthropic\n",
    "# tools = [\n",
    "#     {\n",
    "#         \"name\": \"search_papers\",\n",
    "#         \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "#         \"input_schema\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"topic\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"The topic to search for\"\n",
    "#                 }, \n",
    "#                 \"max_results\": {\n",
    "#                     \"type\": \"integer\",\n",
    "#                     \"description\": \"Maximum number of results to retrieve\",\n",
    "#                     \"default\": 5\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"topic\"]\n",
    "#         }\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"extract_info\",\n",
    "#         \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "#         \"input_schema\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"paper_id\": {\n",
    "#                     \"type\": \"string\",\n",
    "#                     \"description\": \"The ID of the paper to look for\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"paper_id\"]\n",
    "#         }\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_papers\",\n",
    "            \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The topic to search for\"\n",
    "                    }, \n",
    "                    \"max_results\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum number of results to retrieve\",\n",
    "                        \"default\": 5\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_info\",\n",
    "            \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"paper_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ID of the paper to look for\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"paper_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ac8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2ddd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() \n",
    "\n",
    "## Claude API setup\n",
    "# client = anthropic.Anthropic()\n",
    "\n",
    "## OpenAI API setup\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(\n",
    "#     api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "\n",
    "# ALIYUN DashScope API setup\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"QWEN_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "model = \"qwen-plus\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,  # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "\n",
    "    # QWEN API\n",
    "    print(\"-\" * 60)\n",
    "    i = 1\n",
    "    first_response = get_response(messages)\n",
    "\n",
    "    print(f\"第{i}轮大模型输出信息：{first_response}\\n\")\n",
    "    assistant_output = first_response.choices[0].message\n",
    "\n",
    "    if assistant_output.content is None:\n",
    "        assistant_output.content = \"\"\n",
    "    messages.append(assistant_output)\n",
    "\n",
    "    # 如果不需要调用工具，则直接返回最终答案\n",
    "    if assistant_output.tool_calls == None:  # 如果模型判断无需调用工具，则将assistant的回复直接打印出来，无需进行模型的第二轮调用\n",
    "        print(f\"无需调用工具，我可以直接回复：{assistant_output.content}\")\n",
    "        return\n",
    "    \n",
    "    # 如果需要调用工具，则进行模型的多轮调用，直到模型判断无需调用工具\n",
    "    while assistant_output.tool_calls != None:\n",
    "        tool_info = {\n",
    "            \"content\": \"\",\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": assistant_output.tool_calls[0].id,\n",
    "        }\n",
    "\n",
    "        tool_name = assistant_output.tool_calls[0].function.name\n",
    "        tool_args = json.loads(assistant_output.tool_calls[0].function.arguments)\n",
    "        \n",
    "        print(f\"模型决定调用工具: {tool_name}，参数: {tool_args}\")\n",
    "        \n",
    "        # 执行你定义的函数\n",
    "        result = execute_tool(tool_name, tool_args)\n",
    "        \n",
    "        # 将工具执行结果添加到消息历史中\n",
    "        tool_info[\"content\"] = result\n",
    "        tool_info[\"name\"] = tool_name\n",
    "\n",
    "        print(f\"工具 {tool_name} 执行结果: {result}\")\n",
    "\n",
    "        messages.append(tool_info)\n",
    "\n",
    "        assistant_output = get_response(messages).choices[0].message\n",
    "        if assistant_output.content is None:\n",
    "            assistant_output.content = \"\"\n",
    "        messages.append(assistant_output)\n",
    "        i += 1\n",
    "        print(f\"第{i}轮大模型输出信息：{assistant_output}\\n\")\n",
    "\n",
    "    print(f\"最终答案：{assistant_output.content}\")\n",
    "\n",
    "    # OpenAI API\n",
    "    # response = client.chat.completions.create(max_tokens = 2024,\n",
    "    #                               model = model, \n",
    "    #                               tools = tools,\n",
    "    #                               messages = messages,\n",
    "    #                               tool_choice='auto')\n",
    "    \n",
    "\n",
    "    # response_message = response.choices[0].message\n",
    "    # tool_calls = response_message.tool_calls\n",
    "\n",
    "    # # 检查模型是否决定调用工具\n",
    "    # if tool_calls:\n",
    "    #     # 将模型的回复（包含工具调用请求）添加到消息历史中\n",
    "    #     messages.append(response_message)\n",
    "\n",
    "    #     # 执行工具调用\n",
    "    #     for tool_call in tool_calls:\n",
    "    #         tool_name = tool_call.function.name\n",
    "    #         tool_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "    #         print(f\"模型决定调用工具: {tool_name}，参数: {tool_args}\")\n",
    "            \n",
    "    #         # 执行你定义的函数\n",
    "    #         result = execute_tool(tool_name, tool_args)\n",
    "            \n",
    "    #         # 将工具执行结果添加到消息历史中\n",
    "    #         messages.append(\n",
    "    #             {\n",
    "    #                 \"tool_call_id\": tool_call.id,\n",
    "    #                 \"role\": \"tool\",\n",
    "    #                 \"name\": tool_name,\n",
    "    #                 \"content\": result,\n",
    "    #             }\n",
    "    #         )\n",
    "        \n",
    "    #     # 再次调用模型，让它根据工具返回的结果生成最终回复\n",
    "    #     second_response = client.chat.completions.create(\n",
    "    #         model=model,\n",
    "    #         messages=messages,\n",
    "    #     )\n",
    "    #     final_response = second_response.choices[0].message.content\n",
    "    #     print(f\"最终回复: {final_response}\")\n",
    "\n",
    "    # else:\n",
    "    #     # 如果模型没有调用工具，直接打印它的回复\n",
    "    #     final_response = response_message.content\n",
    "    #     print(f\"最终回复: {final_response}\")\n",
    "\n",
    "    # anthropic API\n",
    "    # response = client.messages.create(max_tokens = 2024,\n",
    "    #                               model = 'claude-3-7-sonnet-20250219', \n",
    "    #                               tools = tools,\n",
    "    #                               messages = messages)\n",
    "\n",
    "    # res_content = response.content\n",
    "    # process_query = True\n",
    "    # while process_query:\n",
    "    #     assistant_content = []\n",
    "\n",
    "    #     for content in res_content:\n",
    "    #         if content.type == 'text':\n",
    "                \n",
    "    #             print(content.text)\n",
    "    #             assistant_content.append(content)\n",
    "                \n",
    "    #             if len(res_content) == 1:\n",
    "    #                 process_query = False\n",
    "            \n",
    "    #         elif content.type == 'tool_use':\n",
    "                \n",
    "    #             assistant_content.append(content)\n",
    "    #             messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "    #             tool_id = content.id\n",
    "    #             tool_args = content.input\n",
    "    #             tool_name = content.name\n",
    "    #             print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "    #             result = execute_tool(tool_name, tool_args)\n",
    "    #             messages.append({\"role\": \"user\", \n",
    "    #                               \"content\": [\n",
    "    #                                   {\n",
    "    #                                       \"type\": \"tool_result\",\n",
    "    #                                       \"tool_use_id\": tool_id,\n",
    "    #                                       \"content\": result\n",
    "    #                                   }\n",
    "    #                               ]\n",
    "    #                             })\n",
    "    #             response = client.responses.create(max_tokens = 2024,\n",
    "    #                               model = 'gpt-4.1', \n",
    "    #                               tools = tools,\n",
    "    #                               messages = messages) \n",
    "    #             res_content = response.content\n",
    "\n",
    "    #             if len(res_content) == 1 and res_content[0].type == \"text\":\n",
    "    #                 print(res_content[0].text)\n",
    "    #                 process_query = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f413a666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "第1轮大模型输出信息：ChatCompletion(id='chatcmpl-b0d29e93-860a-95d1-a33f-b928fead1828', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_952a27b6cc9c450787e328', function=Function(arguments='{\"topic\": \"quantum computing\"}', name='search_papers'), type='function', index=0)]))], created=1750674576, model='qwen-plus', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=184, total_tokens=206, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))\n",
      "\n",
      "模型决定调用工具: search_papers，参数: {'topic': 'quantum computing'}\n",
      "Results are saved in: papers/quantum_computing/papers_info.json\n",
      "工具 search_papers 执行结果: 2208.00733v1, quant-ph/0003151v1, 1311.4939v1, 1210.0736v1, 1610.02500v1\n",
      "第2轮大模型输出信息：ChatCompletionMessage(content='Here are some of the latest papers on quantum computing:\\n\\n1. Paper with id: 2208.00733v1\\n2. Paper with id: quant-ph/0003151v1\\n3. Paper with id: 1311.4939v1\\n4. Paper with id: 1210.0736v1\\n5. Paper with id: 1610.02500v1\\n\\nWould you like more information on any of these?', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n",
      "\n",
      "最终答案：Here are some of the latest papers on quantum computing:\n",
      "\n",
      "1. Paper with id: 2208.00733v1\n",
      "2. Paper with id: quant-ph/0003151v1\n",
      "3. Paper with id: 1311.4939v1\n",
      "4. Paper with id: 1210.0736v1\n",
      "5. Paper with id: 1610.02500v1\n",
      "\n",
      "Would you like more information on any of these?\n"
     ]
    }
   ],
   "source": [
    "process_query(\"What are the latest papers on quantum computing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8f90910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e9ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
